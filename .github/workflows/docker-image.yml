name: Docker Image CI

on:
  push:
    branches: [ "master" ]

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}
        
    - name: Build and push App image
      uses: docker/build-push-action@v5
      with:
        context: ./app
        push: true
        tags: |
          ${{ secrets.DOCKERHUB_USERNAME }}/log-service:latest
          ${{ secrets.DOCKERHUB_USERNAME }}/log-service:${{ github.sha }}
          
    - name: Build and push Producer image
      uses: docker/build-push-action@v5
      with:
        context: ./producer
        push: true
        tags: |
          ${{ secrets.DOCKERHUB_USERNAME }}/kafka-producer:latest
          ${{ secrets.DOCKERHUB_USERNAME }}/kafka-producer:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    
    steps:
    - name: Deploy to EC2
      uses: appleboy/ssh-action@master
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ec2-user
        key: ${{ secrets.EC2_SSH_KEY }}
        script: |
          # Pull the latest images
          docker pull ${{ secrets.DOCKERHUB_USERNAME }}/log-service:latest
          docker pull ${{ secrets.DOCKERHUB_USERNAME }}/kafka-producer:latest
          
          # Stop and remove existing containers
          docker-compose down || true
          
          # Create docker-compose.yml with strict resource limits
          cat > docker-compose.yml << 'EOL'
          services:
            mongo:
              image: mongo
              container_name: mongodb
              ports:
                - '27017:27017'
              restart: unless-stopped
              environment:
                MONGO_INITDB_ROOT_USERNAME: admin
                MONGO_INITDB_ROOT_PASSWORD: password
              volumes:
                - mongo-data:/data/db
              deploy:
                resources:
                  limits:
                    memory: 200M
          
            zookeeper:
              image: confluentinc/cp-zookeeper:latest
              container_name: zookeeper
              environment:
                ZOOKEEPER_CLIENT_PORT: 2181
                ZOOKEEPER_TICK_TIME: 2000
              ports:
                - '2181:2181'
              volumes:
                - zookeeper-data:/var/lib/zookeeper/data
              deploy:
                resources:
                  limits:
                    memory: 100M
          
            kafka:
              image: confluentinc/cp-kafka:latest
              container_name: kafka
              depends_on:
                - zookeeper
              ports:
                - '9092:9092'
                - '29092:29092'
              environment:
                KAFKA_BROKER_ID: 1
                KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
                KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
                KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
                KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
                KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
                KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
                # Explicitly define listeners to avoid default binding to 0.0.0.0
                KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
                # Reduce memory usage
                KAFKA_HEAP_OPTS: "-Xmx200m -Xms100m"
              deploy:
                resources:
                  limits:
                    memory: 200M
          
            app:
              image: ${{ secrets.DOCKERHUB_USERNAME }}/log-service:latest
              container_name: app
              ports:
                - '3000:3000'
              depends_on:
                - kafka
                - mongo
              environment:
                PORT: 3000
                DATABASE_URL: mongodb://<db_username>:<db_password>@mongo:27017
                DATABASE_USERNAME: admin
                DATABASE_PASSWORD: password
                # Reduce Node.js memory usage
                NODE_OPTIONS: "--max-old-space-size=100"
              deploy:
                resources:
                  limits:
                    memory: 100M
              restart: unless-stopped
          
            kafka_producer:
              image: ${{ secrets.DOCKERHUB_USERNAME }}/kafka-producer:latest
              container_name: kafka_producer
              depends_on:
                - app
              environment:
                # Reduce Node.js memory usage
                NODE_OPTIONS: "--max-old-space-size=50"
              deploy:
                resources:
                  limits:
                    memory: 50M
              restart: unless-stopped
          
          volumes:
            mongo-data:
            zookeeper-data:
            kafka-data:
          EOL
          
          # Start the containers
          docker-compose up -d
          
          # Set up automatic shutdown during non-working hours to save hours
          # This will shut down the instance at 8 PM UTC daily
          (crontab -l 2>/dev/null; echo "0 20 * * * sudo shutdown -h now") | crontab -